[//]: # (
 
 Language in brain,
 LLM in brain,

 neuronavigation

 NeuroAI


 cerebellum embodied intelligence
    
    )

<style>
.container{
    display: flex;
}
.col{
    flex: 1;
}
</style>

##### Early Exploration of
#### Brain-Inspired Navigation & Spatial Intelligence

LI Shaun, ZHU Xiangwei

2024-12-09

<!-- .element: style="font-size:20pt" -->

=== 


<iframe width="1280" height="720" src="https://www.youtube.com/embed/-icD_KmvnnM?start=115" title="First Reactions | Geoffrey Hinton, Nobel Prize in Physics 2024 | Telephone interview" frameborder="0" allow="accelerometer; autoplay; clipboard-write; encrypted-media; gyroscope; picture-in-picture; web-share" referrerpolicy="strict-origin-when-cross-origin" allowfullscreen></iframe>

==

*I am someone who just really knows what field he’s in but would like to **understand how the brain works**<!-- .element style="color:#ffde64"-->. And in my attempts to understand how the brain works, I’ve helped to create a technology that works surprisingly well.* <!-- .element: style="float: left; width: 67%; padding-right:1em;  text-align: justify;" -->

![alt text](https://www.nobelprize.org/uploads/2024/10/2-2_3-6704d5430e393-464x696.jpg) <!-- .element: style="width: 25%" -->

===

### Why Brain-Inspired?

Harness the efficiency and sophistication refined <br> over **hundreds of millions of years**<!-- .element style="color:#FFED64"--> of evolution
<!-- .element: style="font-size:26pt" -->

==

![alt text](images/chengjiang.jpg) <!-- .element: height="600" --> 

===

### What brain-inspired has achieved?


| **AI Algorithms**        | **Time** | **Neuroscience Discoveries**            | **Time**  |
|------------------------|----------|----------------------------|-----------|
| Multilayer Perceptron | 1950s    | Structure of neocortex     | 1860s-1950s |
| Convolutional Neural Network  | 1980     | Cat's visual mechanism | 1962      |
| Recurrent Neural Network  | 1980s      | Recurrent synapses in brain| 1947 |
| Reinforcement Learning   | 1950s-1970s | Reinforcement theory | 1898      |
| Backpropagation Algorithm | 1986     | Retrograde neurotransmitter| 1990s |
<!-- .element: style="font-size:18pt" -->

===



### Two stories
- Multilayer perceptron
- Backpropagation <!-- .element: style="color:gray" -->

==

### Nissl stain & Golgi stain

![alt text](images/nissl.png)<!-- .element: height="300" --> 
![alt text](images/golgi.png)<!-- .element: height="300" -->

*The gain in brain is mainly in the stain.*

**Neurons communicate by contact or continuity?**  <!-- .element style="color:#FFED64"-->
==

![golgi-cajal](https://www.frontiersin.org/files/Articles/434842/fncel-13-00187-HTML/image_m/fncel-13-00187-g001.jpg)<!-- .element: height="600" -->

==


![alt text](images/electron-microscope.png)

**Neurites in contact, not continuity**<!-- .element style="color:#FFED64"--><br>by electron microscopy (1950s)

==

![alt text](images/neocortex.png)<!-- .element: height="500" -->

The multilayer structure of the neocortex (1950s)


==

![rosenblatt](images/rosenblatt.png)

Frank Rosenblatt and his Perceptron (1958)


===
### Two stories
- Multilayer perceptron<!-- .element: style="color:gray" -->
- Backpropagation 
==

![kinesin](https://i.makeagif.com/media/11-08-2022/oUjMFB.gif)

Anterograde and retrograde transport inside neurons<br>with kinesin and dynein


==

![alt text](images/cannoboid.png)<!-- .element: height="500" -->

Retrograde messengers between neurons: Anandamide, NO, CO, H₂S
===

![NeuroAI](images/neuroai.png) 

==
### Challenges of Today's AI

- Environments
- Efficiency
- Flexibility

==

### Solution: Neuroscience x AI
Neurocomputing and Embodied Intelligence

![ett](images/e-turing-test.png) <!-- .element: height="200" -->

==

#### Computational Neuroscience vs. NeuroAI?

===

### Outline
- Introduction<!-- .element: style="color:gray" -->
- Brain-Inspired Navigation
    - Intension
    - Extension
    - Relationship with Spatial Intelligence
- Spatial Intelligence
    - Etymology
    - Examples
    - Relationship with Embodied Intelligence

===


### What is Brain-Inspired Navigation

Navigation technology inspired by neuroscience



==
![alt text](images/neuraltube.png)<!-- .element: height="500" -->

Formation of the neural tube and neural crest

==

![alt text](images/thumbtack.png)

A simple reflex

==

#### Navigation technology inspired by neuroscience

Not limited to "brain", but on the entire nervous system
<!-- .element: style="font-size:30pt;color:#ffde64" -->
===

### The Extension of Neuronavigation

![alt text](images/animals.png)<!-- .element: height="250" --> $\quad$ ![alt text](images/levels.png)<!-- .element: height="250" --> 


Horizontal $\quad\quad\quad\quad\quad\quad$ Vertical $\quad\quad$
===


### Horizontal: The animals that inspire us

![alt text](images/animals.png)<!-- .element: height="350" -->

Insects, birds, mammals, etc.
==


![desert ant](https://www.epj.org/images/stories/news/2022/11734_2022_610_Fig4.png) <!-- .element: height="500" -->

Sahara Desert ant: Path integration

==

![bird](https://th-thumbnailer.cdn-si-edu.com/Mp2iSv6cnH7egOfFsgty5IEl7tI=/1000x750/filters:no_upscale()/https://tf-cmsv2-smithsonianmag-media.s3.amazonaws.com/filer/Phenom-Home-bird-flight-631.jpg)

Bird: Multimodal
==

![nobel2014](https://ysm-res.cloudinary.com/image/upload/c_limit,f_auto,h_630,q_auto,w_1200/v1/yms/prod/94115fdc-2630-4b90-b674-c538441f95a1)<!-- .element: height="250" --> <iframe width="300" height="250" src="https://www.youtube.com/embed/i9GiLBXWAHI" title="grid cell movie" frameborder="0" allow="accelerometer; autoplay; clipboard-write; encrypted-media; gyroscope; picture-in-picture; web-share" referrerpolicy="strict-origin-when-cross-origin" allowfullscreen></iframe>

Rat: [The grid cell](https://www.numenta.com/blog/2018/05/25/how-grid-cells-map-space/)

==
<iframe width="800" height="600" src="https://www.youtube.com/embed/-7ijI-g4jHg?start=5" title="Bee Dance (Waggle Dance)" frameborder="0" allow="accelerometer; autoplay; clipboard-write; encrypted-media; gyroscope; picture-in-picture; web-share" referrerpolicy="strict-origin-when-cross-origin" allowfullscreen></iframe>

Swarm intelligence: waggle dance
==

<iframe width="1512" height="500" src="https://www.youtube.com/embed/V4f_1_r80RY" title="Flight of the Starlings: Watch This Eerie but Beautiful Phenomenon | Short Film Showcase" frameborder="0" allow="accelerometer; autoplay; clipboard-write; encrypted-media; gyroscope; picture-in-picture; web-share" referrerpolicy="strict-origin-when-cross-origin" allowfullscreen></iframe>

Swarm intelligence: Starlings
===

### Vertical: Levels of analysis and design

![alt text](images/levels.png)<!-- .element: height="450" --> 

===

### Basics of neuroscience

==

![alt text](images/cells.png)<!-- .element: height="500" -->

The cell

==

![alt text](images/cells-neurons.png)<!-- .element: height="500" -->

The neuron

==
![alt text](images/rest-potential.png)<!-- .element: height="500" -->

Na/K ion pumps

==
![alt text](images/rest-potential2.png)<!-- .element: height="400" -->

Rest potential

==

![alt text](images/action-potential.png)<!-- .element: height="500" -->

Action potential

==
![alt text](images/synapse.png)<!-- .element: height="500" -->

The synapse
==

![alt text](images/EPSP.png)<!-- .element: height="500" -->

EPSP: Excitatory postsynaptic potential

==

![alt text](images/IPSP.png)<!-- .element: height="500" -->

IPSP: Inhibitory postsynaptic potential

==
![alt text](images/synaptic-integration.png)<!-- .element: height="400" -->

The linear part: Synaptic integration

==

![alt text](images/g-protein-modulation.png)<!-- .element: height="400" -->

The non-linear part: G-protein modulation

===


### Vertical: Levels of analysis and design

![alt text](images/levels.png)<!-- .element: height="450" --> 

==

![alt text](images/spiking-neuron.png)

The spiking mechanism
==

![alt text](images/crossbar.png) <!-- .element: height="450" --> 

The Epsilon Neural Network on a crossbar

==

![alt text](images/VBN.png) <!-- .element: height="450" --> 

DeepMind: Vector-based navigation (VBN)

*Navigating with grid-like representations in artificial agents, Nature*
<!-- .element: style="text-align: right;font-size:15pt" -->

==


<iframe width="800" height="600" src="https://www.youtube.com/embed/kPCZESVfHoQ?start=5" title="Event-Based Camera vs Standard Camera" frameborder="0" allow="accelerometer; autoplay; clipboard-write; encrypted-media; gyroscope; picture-in-picture; web-share" referrerpolicy="strict-origin-when-cross-origin" allowfullscreen></iframe>

Event-based camera

==

![alt text](images/event-camera.jpeg) <!-- .element: height="450" --> 

Event-based camera

==

![alt text](images/yu-etal.png) <!-- .element: height="450" --> 

Yu et al. *Brain-Inspired Multimodal Hybrid Neural Network for Robot Place Recognition. Sci. Rob.* 2023
<!-- .element: style="text-align: right;font-size:15pt" -->

==

![alt text](images/insect-behavior.png) <!-- .element: height="450" --> 

Delft: A tiny drone


==

<iframe width="800" height="600" src="https://www.youtube.com/embed/J0qh9gu9Tko?start=39" title="Visual Route-following for Tiny Autonomous Robots - Science Robotics" frameborder="0" allow="accelerometer; autoplay; clipboard-write; encrypted-media; gyroscope; picture-in-picture; web-share" referrerpolicy="strict-origin-when-cross-origin" allowfullscreen></iframe>

===


### Vertical: Levels of analysis and design

![alt text](images/levels.png)<!-- .element: height="450" --> 

===

### Spatial Intelligence
Towards cognitive navigation

==
<iframe width="1512" height="688" src="https://www.youtube.com/embed/y8NtMZ7VGmU?start=346" title="With Spatial Intelligence, AI Will Understand the Real World | Fei-Fei Li | TED" frameborder="0" allow="accelerometer; autoplay; clipboard-write; encrypted-media; gyroscope; picture-in-picture; web-share" referrerpolicy="strict-origin-when-cross-origin" allowfullscreen></iframe>


===


![howard-gardner](https://images.squarespace-cdn.com/content/v1/600727b753a1396eba98dd48/0974cc26-ace6-41c2-bd49-8b1351998605/HG+1+Summer+2016_credit+HGSE.JPG)<!-- .element: height="400" -->$\quad$
![frame-of-mind](https://m.media-amazon.com/images/I/718ThpPJeSL.jpg)<!-- .element: height="400" --> 

Spatial Intelligence by Howard Gardner in 1983

==
![frame-of-mind](images/rotation.png)<!-- .element: height="500" --> 

Whether the second form is a rotation of the first

==

![alt text](images/stairs.png) <!-- .element: height="500" --> 

Upstairs or downstairs?

==

![alt text](images/binocular.png) <!-- .element: height="500" --> 

Stereo vision due to binocular disparity?

==

*There is a distance—but a **navigable**<!-- .element style="color:#ffde64"--> one—between this elementary recognition of objects and that ability to trace the relationships among objects that proves central in **spatial intelligence**<!-- .element style="color:#ffde64"-->.*<!-- .element: style="float: left; width: 75%; padding-right:1em;  text-align: left;" -->

![frame-of-mind](https://m.media-amazon.com/images/I/718ThpPJeSL.jpg) <!-- .element: style="width: 18%" -->


==

![micronesia](https://upload.wikimedia.org/wikipedia/commons/thumb/8/87/Oceania_UN_Geoscheme_-_Map_of_Micronesia.svg/1920px-Oceania_UN_Geoscheme_-_Map_of_Micronesia.svg.png)

Micronesian navigation

===

<iframe width="800" height="600" src="https://reconfusion.github.io/videos/results/co3d_3x5.mp4" title="First Reactions | Geoffrey Hinton, Nobel Prize in Physics 2024 | Telephone interview" frameborder="0" allow="accelerometer; autoplay; clipboard-write; encrypted-media; gyroscope; picture-in-picture; web-share" referrerpolicy="strict-origin-when-cross-origin" allowfullscreen></iframe>


*Wu et al. ReconFusion: 3D Reconstruction with Diffusion Priors, CVPR 2024* <!-- .element: style="text-align: right;font-size:15pt" -->


==

![hourvideo](https://hourvideo.stanford.edu/static/images/hourvideo_at_a_glance.001.jpeg)

[HourVideo](https://hourvideo.stanford.edu/): the ImageNet of spatial intelligence

==

<iframe width="800" height="600" src="https://wlt-ai-cdn.art/videos/banner_video.mp4" frameborder="0" allow="accelerometer; autoplay; clipboard-write; encrypted-media; gyroscope; picture-in-picture; web-share" referrerpolicy="strict-origin-when-cross-origin" allowfullscreen></iframe>

Li Fei-Fei's [World Labs](https://www.worldlabs.ai/blog)

===

##### Early Exploration of
#### Brain-Inspired Navigation & Spatial Intelligence

LI Shaun, ZHU Xiangwei

2024-12-16

<!-- .element: style="font-size:20pt" -->

===

![alt text](images/levels.png)<!-- .element: height="450" --> 

==

![brain](https://kidspressmagazine.com/wp-content/uploads/2014/06/dreamstime_m_36838484EDITED.jpg) <!-- .element: height="650" --> 
==

### Q&A: Compare MLP, KAN, SNN


===

### Embodied Intelligence
![embodiedai](https://sos-ch-dk-2.exo.io/public-website-production-2022/filer_public/1b/41/1b41a815-05bf-4ef9-88b9-50d268831950/alex-knight-2ejcsulrwc8-unsplash.jpg)<!-- .element: height="350" --> 

===


## embody

em-/en- : to make something have a particular quality
<!-- .element: style="font-size:24pt" -->

Compare: empower

word family: embody (v.), embodied (adj.), embodiment (n.)
<!-- .element: style="font-size:24pt" -->

===

<video loop autoplay="" muted="" playsinline="" preload="metadata">
                <source src="https://general-navigation-models.github.io/vint/static/videos/teaser.mp4" type="video/mp4">
            </video>

[ViNT: A Foundation Model for Visual Navigation](https://general-navigation-models.github.io/vint/)

==
![Open X-Embodiment](https://robotics-transformer-x.github.io/img/overview.png)
[Open X-Embodiment: Robotic Learning Datasets and RT-X Models](https://robotics-transformer-x.github.io/)


==

![extreme](https://extreme-cross-embodiment.github.io/static/images/teaser.png)

[Extreme Cross-Embodiment Learning for Manipulation and Navigation](https://extreme-cross-embodiment.github.io/)

===
## Embodied AI $\overset{?}{=}$ Robotics



==
### Embodied agents generalize to ...
- WHERE -- Navigation 
- WHAT -- Manipulation
- WHO -- Cross-embodiment

===




*Many people think that a very abstract activity, like the playing of chess, would be best.  It can also be maintained that it is best to provide the machine with the best sense organs that money can buy, and then teach it to understand and speak English.  This process could follow the normal teaching of a child.  Things would be pointed out and named, etc. Again I do not know what the right answer is, but I think both approaches should be tried.*
<!-- .element: style="float: left; width: 75%; padding-right:1em; text-align: justify;" -->


![Turing](https://collectionimages.npg.org.uk/std/mw63680/Alan-Turing.jpg)<!-- .element: style="width: 20%" -->

Alan Turing, *Computing Machinery and Intelligence* (1950)
<!-- .element: style="font-size:16pt" -->


==
### Embodied vs Disembodied 

*Both approaches should be tried.*

Note:( 思维 vs 行为)

==

### Moravec's Paradox


Hard problems are easy; easy problems are hard.

*It is comparatively easy to make computers exhibit adult level performance on intelligence tests or playing checkers, and difficult or impossible to give them the skills of a one-year-old when it comes to perception and mobility* (1988)
<!-- .element: style="float: left; width: 60%; padding-right:1em; text-align: justify;" -->

![moravec](https://www.onthisday.com/images/people/hans-moravec.jpg?w=360) <!-- .element: style="width: 30%" -->



==

![bishop](https://i.pinimg.com/736x/c4/dc/9e/c4dc9e42d76a2507c0a25497338593bd.jpg)<!-- .element: height="300" --> $\quad$
![brooks](https://people.csail.mit.edu/brooks/all%20images/company%20images/brooks_sept_2021.jpg) <!-- .element: height="300" --> 
### *Elephants don't play chess* (1990)
Rodney Brooks


==

Paradigms of AI
- Symbolism
- Connectionism
- Actionism


==

不聞不若聞之，聞之不若見之，見之不若知之，知之不若行之，學至於行之而止矣。

——《荀子·儒效》
<!-- .element: style="font-size:18pt;text-align:right" -->
<br />


紙上得來終覺淺，絕知此事要躬行。


—— 陸游 《冬夜讀書示子聿》
<!-- .element: style="font-size:18pt;text-align:right" -->  

<br />

知之愈明，則行之愈篤；行之愈篤，則知之益明.

—— 朱熹 《朱子語類》
<!-- .element: style="font-size:18pt;text-align:right" -->


<!-- .slide: style="font-size:24pt" -->
===




<img class="r-stretch" src="http://2.bp.blogspot.com/-xYAEEyxjhuk/Tut2TaFzUtI/AAAAAAAAACw/G7VndH6VHKM/s1600/%25E3%2582%25B4%25E3%2583%25B3%25E3%2583%2589%25E3%2583%25A9%25E3%2583%258D%25E3%2582%25B3.jpg">

Classic experiment by Held and Hein (1963)



==

*We are told that vision depends on the eye, which is connected to the brain.
I shall suggest that natural vision depends on the eyes in the head on a body supported by the ground, the brain being only the central organ of a complete visual system.*
   <!-- .element: style="float: left; width: 60%; padding-right:1em; text-align: justify;" -->


![gibson](https://encrypted-tbn0.gstatic.com/images?q=tbn:ANd9GcSVZovKTCMAVz7bktP3kGq8mG9F8ocFQTOrKw&s)

James J. Gibson, *The Ecological Approach to Visual Perception* (1979)
<!-- .element: style="font-size:18pt" -->

==


#### *You can't learn language from the radio.*
Similar metaphor in NLP


==
![cartesian](https://upload.wikimedia.org/wikipedia/commons/thumb/9/94/Cartesian_Cognitive_Model.png/440px-Cartesian_Cognitive_Model.png) $\quad$
![embodied](https://upload.wikimedia.org/wikipedia/commons/thumb/e/e0/Dynamical_Embodied_Model_of_Cognition.png/440px-Dynamical_Embodied_Model_of_Cognition.png)

### Cognition is embodied
Intelligence emerges in the interaction of an agent with an environment and as a result of sensorimotor activity.

==

### The trend of embodied AI
With a body $\implies$ Embodied

===





## Embodied Turing Test


![Alt text](images/e-turing-test.png)
Ref: [Zador et al.](https://www.nature.com/articles/s41467-023-37180-x)



===


<video loop="" autoplay="" muted="" playsinline="" preload="metadata">
                <source src="https://robotic-pretrained-transformer.github.io/assets/method_animation_v4.m4v" type="video/mp4">
            </video>
            Pretraining: Mask autoencoding

==

<video loop="" autoplay="" muted="" playsinline="" preload="metadata">
                <source src=" https://robotic-pretrained-transformer.github.io/assets/inference_animation.mp4" type="video/mp4">
            </video>

Inference: Autoregressive

===

#### Both Embodied & Spatial  are spatial-temporal
- Embodied Intelligence: Time to Space
- Spatial Intelligence: Space to Time


===

### Coda: Quo vadis?

===

![Alt text](images/hippocampus.png)<!-- .element: height="500" --> 

Cognitive Navigation: Connecting hippocampus to cortex
<!-- .element: style="font-size:20pt" -->

==

![Alt text](images/navgpt.png)
NavGPT, Discuss before Move


==

*It is only proper to realize that language is largely a historical accident.*  <!-- .element: style="float: left; width: 50%; padding-right:1em; text-align: justify;" -->


![vonneumann](https://i.guim.co.uk/img/static/sys-images/Observer/Pix/pictures/2012/2/23/1330005410449/John-von-Neumann-and-the--007.jpg?width=465&dpr=1&s=none&crop=none) <!-- .element: style="width: 30%" -->

John von Neumann, *The Computer and the Brain* (1958)
<!-- .element: style="font-size:16pt" -->
===
![octopus](https://i.pinimg.com/originals/7f/73/30/7f7330cd395a1a73565f6e6e14babeaa.gif)
![octo](https://media3.giphy.com/media/ymFiKhGpikeoReG6wT/200w.gif?cid=6c09b952bdzo3m6qfu9zvqlxx6s895w7w7zp3t4owjhfdpto&ep=v1_gifs_search&rid=200w.gif&ct=g)

Octopus's camouflage
===

![questions](https://media.licdn.com/dms/image/C4D12AQF2HyN6MILFGw/article-cover_image-shrink_720_1280/0/1646657644961?e=2147483647&v=beta&t=O7HBRXmp-4I1vnw3p8_2THSzNzPtA7cS76_5yrCfZrY)